<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="hadoop, RedHat, wordcount," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="本文中所有x xxx均为未知 须根据你得具体版本号来决定  创建用户groupadd hadoop_user useradd -g hadoop_user -d /home/hadoop hadoop passwd hadoop  配置YUM源  Redhat 的更新包只对注册的用户生效，所以我们需要自己手动更改成CentOS的更新包，CentOS几乎和redhat是一样的，所以无需担心软件包是">
<meta name="keywords" content="hadoop, RedHat, wordcount">
<meta property="og:type" content="article">
<meta property="og:title" content="hadoopRedHatLab2">
<meta property="og:url" content="http://zyad86.g  ithub.io/2017/04/20/lab-redhat-hadoop/index.html">
<meta property="og:site_name" content="zyad86-Hexo">
<meta property="og:description" content="本文中所有x xxx均为未知 须根据你得具体版本号来决定  创建用户groupadd hadoop_user useradd -g hadoop_user -d /home/hadoop hadoop passwd hadoop  配置YUM源  Redhat 的更新包只对注册的用户生效，所以我们需要自己手动更改成CentOS的更新包，CentOS几乎和redhat是一样的，所以无需担心软件包是">
<meta property="og:updated_time" content="2017-04-20T16:12:45.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="hadoopRedHatLab2">
<meta name="twitter:description" content="本文中所有x xxx均为未知 须根据你得具体版本号来决定  创建用户groupadd hadoop_user useradd -g hadoop_user -d /home/hadoop hadoop passwd hadoop  配置YUM源  Redhat 的更新包只对注册的用户生效，所以我们需要自己手动更改成CentOS的更新包，CentOS几乎和redhat是一样的，所以无需担心软件包是">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://zyad86.g  ithub.io/2017/04/20/lab-redhat-hadoop/"/>





  <title> hadoopRedHatLab2 | zyad86-Hexo </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">zyad86-Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">trace of development</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://zyad86.g  ithub.io/2017/04/20/lab-redhat-hadoop/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ericyz-zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zyad86-Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                hadoopRedHatLab2
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-20T10:41:02+08:00">
                2017-04-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <blockquote>
<p>本文中所有x xxx均为未知 须根据你得具体版本号来决定</p>
</blockquote>
<h2 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h2><pre><code>groupadd hadoop_user
useradd -g hadoop_user -d /home/hadoop hadoop
passwd hadoop 
</code></pre><h2 id="配置YUM源"><a href="#配置YUM源" class="headerlink" title="配置YUM源"></a>配置YUM源</h2><p>  Redhat 的更新包只对注册的用户生效，所以我们需要自己手动更改成CentOS的更新包，CentOS几乎和redhat是一样的，所以无需担心软件包是否可安装，安装之后是否有问题。</p>
<p>1、 首先删除redhat原有的yum ，因为redhat 原本的yum 没有注册为redhat用户是用不了的。</p>
<pre><code>rpm -aq|grep yum|xargs rpm -e --nodeps
rpm -aq|grep python-iniparse|xargs rpm -e --nodeps
</code></pre><p>2、下载163的yum 安装包</p>
<pre><code>wget http://mirrors.163.com/centos/7.3.1611/os/x86_64/Packages/
yum-3.4.3-150.el7.centos.noarch.rpm
wget http://mirrors.163.com/centos/7.3.1611/os/x86_64/Packages/
python-iniparse-0.4-9.el7.noarch.rpm
wget http://mirrors.163.com/centos/7.3.1611/os/x86_64/Packages/
yum-metadata-parser-1.1.4-10.el7.x86_64.rpm
wget http://mirrors.163.com/centos/7.3.1611/os/x86_64/Packages/
yum-plugin-fastestmirror-1.1.31-40.el7.noarch.rpm
</code></pre><p>3、安装下载的rpm包</p>
<pre><code>rpm -ivh *.rpm
</code></pre><p>4、创建文件/etc/yum.repos.d/rhel-debuginfo.repo并写入</p>
<pre><code>[base]
name=CentOS-$releasever - Base
baseurl=http://mirrors.163.com/centos/7.3.1611/os/$basearch/
gpgcheck=1
gpgkey=http://mirrors.163.com/centos/7.3.1611/os/x86_64/RPM-GPG-
KEY-CentOS-7


#released updates
[updates]
name=CentOS-$releasever - Updates
baseurl=http://mirrors.163.com/centos/7.3.1611/updates/$basearch/
gpgcheck=1
gpgkey=http://mirrors.163.com/centos/7.3.1611/os/x86_64/RPM-GPG-
KEY-CentOS-7


[extras]
name=CentOS-$releasever - Extras
baseurl=http://mirrors.163.com/centos/7.3.1611/extras//$basearch/
gpgcheck=1
gpgkey=http://mirrors.163.com/centos/7.3.1611/os/x86_64/RPM-GPG-
KEY-CentOS-7

[centosplus]
name=CentOS-$releasever - Plus
baseurl=http://mirrors.163.com/centos/7.3.1611/centosplus//$basearch/
gpgcheck=1
enabled=0
</code></pre><p>6、执行命令</p>
<pre><code>yum clean all
</code></pre><p>7、测试：</p>
<pre><code>yum update
</code></pre><p>8、 安装 epel 源：</p>
<pre><code>yum install epel-release    
</code></pre><h2 id="添加sudoer"><a href="#添加sudoer" class="headerlink" title="添加sudoer"></a>添加sudoer</h2><p>当用户不在sudoers文件中……</p>
<p>处理这个问题很简单，但应该先理解其原理再操作</p>
<p>首先要明白root的密码一般用户是不应改知道的，但一般用户有时可能要用到root的一些权限。</p>
<p>这里就有了一个 /etc/sudoers文件，用来保存一些用户，使这些用户可以通过sudo命令来暂时获取root的权限。这些用户使用sudo时输入的密码是当前用户密码，而不是root密码。还可一在sudoers文件里限制一般用户的权限，这样就有了安全保证。</p>
<p>现在要让hadoop用户获得sudo使用权</p>
<p>1.切换到超级用户root</p>
<pre><code>$su root
</code></pre><p>2.查看/etc/sudoers权限，可以看到当前权限为440</p>
<pre><code>$ ls -all /etc/sudoers
   -r--r----- 1 root root744  6月  8 10:29/etc/sudoers
</code></pre><p>3.更改权限为777</p>
<pre><code>$chmod 777/etc/sudoers
</code></pre><p>4.编辑/etc/sudoers</p>
<pre><code>$vi /etc/sudoers
</code></pre><p>5.在root   ALL=(ALL:ALL) ALL 下面添加一行</p>
<pre><code>hadoop   ALL=(ALL)ALL
</code></pre><p>   保存退出。<br>   第一个ALL是指网络中的主机，我们后面把它改成了主机名，它指明jack可以在此主机上执行后 面的命令。</p>
<p>   第二个括号里的ALL是指目标用户，也就是以谁的身份去执行命令。<br>   最后一个ALL当然就是指命令名了。<br>   具体这里不作说明</p>
<p>6.把/etc/sudoers权限改回440</p>
<pre><code>$chmod 440 /etc/sudoers
</code></pre><p>7.操作完成，切换到hadoop用户测试一下</p>
<h2 id="ssh免密码"><a href="#ssh免密码" class="headerlink" title="ssh免密码"></a>ssh免密码</h2><pre><code>cd ~/.ssh/
ssh-keygen -t rsa  
</code></pre><p>这边一路回车就好</p>
<pre><code>cat ./id_rsa.pub &gt;&gt; ./authorized_keys
</code></pre><p>test:   </p>
<pre><code>ssh localhost 
</code></pre><p>测试一下是否免密码了</p>
<h2 id="jdk环境配置"><a href="#jdk环境配置" class="headerlink" title="jdk环境配置"></a>jdk环境配置</h2><p><a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="external">Java SE Development Kit 8 Downloads</a></p>
<p>按照实验手册的要求我们将它解压到 root/usr/java这个目录下</p>
<p>那么jdk用户目录是 /usr/java/java-xxx （这边视具体情况自己补全吧，下面同</p>
<h3 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h3><pre><code>vim ~/.bashrc
</code></pre><p>在文件最后面加入单独一行</p>
<pre><code>export JAVA_HOME=/usr/java/java-xxx
</code></pre><p>使得环境生效</p>
<pre><code>source ~/.bashrc
</code></pre><p>检验配置是否正确：</p>
<pre><code>echo $JAVA_HOME    # 检验变量值
java -version
$JAVA_HOME/bin/java -version   
</code></pre><p>如果与直接执行 java -version 一样则成功</p>
<h2 id="hadoop单机配置"><a href="#hadoop单机配置" class="headerlink" title="hadoop单机配置"></a>hadoop单机配置</h2><p>记得下载binary版本的</p>
<p><a href="http://hadoop.apache.org/releases.html" target="_blank" rel="external">Hadoop</a></p>
<p>下载完一般没问题，如果出现了奇怪的问题强烈建议check下md5码</p>
<pre><code>mkdir ~/hadoop_installs
</code></pre><p>将下载下来的安装包丢到该目录解压</p>
<pre><code>tar -zxvf hadoop-2.7.x.tar.gz
</code></pre><p>测试文件是否完整，因为是编译好的，解压完就能用</p>
<pre><code>cd /home/hadoop_installs/hadoop-2.7.x
./bin/hadoop version
</code></pre><p>若显示版本号 那就正常了</p>
<h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><p>编辑~/.bashrc</p>
<pre><code>gedit ~/.bashrc
</code></pre><p>添加如下内容： </p>
<pre><code>export HADOOP_HOME=/home/hadoop_installs/hadoop-2.7.x 
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
</code></pre><p>保存后不要忘了执行以下命令使配置生效</p>
<pre><code>source ~/.bashrc
</code></pre><h3 id="hadoop单机运行"><a href="#hadoop单机运行" class="headerlink" title="hadoop单机运行"></a>hadoop单机运行</h3><p>现在我们可以执行例子来感受下 Hadoop 的运行。Hadoop 附带了丰富的例子（运行 ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar 可以看到所有例子），包括 wordcount、terasort、join、grep 等。</p>
<p>在此选择运行 grep 例子，将 input 文件夹中的所有文件作为输入，筛选当中符合正则表达式 dfs[a-z.]+ 的单词并统计出现的次数，最后输出结果到 output 文件夹中。</p>
<pre><code>cd /usr/local/hadoop
mkdir ./input
cp ./etc/hadoop/*.xml ./input   # 将配置文件作为输入文件
./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-
examples-*.jar grep ./input ./output &apos;dfs[a-z.]+&apos;
cat ./output/*          # 查看运行结果
</code></pre><p>此处提示“WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable”，该 WARN 提示可以忽略，不会影响 Hadoop 正常运行（可通过编译 Hadoop 源码解决，解决方法请自行搜索）。 源头是binary是在一个32位的机器上编译的。</p>
<p>若出现提示 “INFO metrics.MetricsUtil: Unable to obtain hostName java.net.UnknowHostException”，这需要执行如下命令修改 hosts 文件，为你的主机名增加IP映射：</p>
<pre><code>sudo vim /etc/hosts
</code></pre><p>在最后面增加一行 “127.0.0.1 dblab”</p>
<p>保存文件后重新运行 hadoop 实例，若执行成功的话会输出很多作业的相关信息，最后的输出信息如下图所示。作业的结果会输出在指定的 output 文件夹中，通过命令 cat ./output/* 查看结果，符合正则的单词 dfsadmin 出现了1次</p>
<h5 id="注意，Hadoop-默认不会覆盖结果文件，因此再次运行上面实例会提示出错，需要先将-output-删除。"><a href="#注意，Hadoop-默认不会覆盖结果文件，因此再次运行上面实例会提示出错，需要先将-output-删除。" class="headerlink" title="注意，Hadoop 默认不会覆盖结果文件，因此再次运行上面实例会提示出错，需要先将 ./output 删除。"></a>注意，Hadoop 默认不会覆盖结果文件，因此再次运行上面实例会提示出错，需要先将 ./output 删除。</h5><pre><code>rm -r ./output
</code></pre><p>这边如果遇上运行后不知道java位置的情况，可以将更改配置文件hadoop-env.sh其中直接写详细的java位置即可 不过这不是根本解决方法 还是检查下自己之前的配置</p>
<h3 id="hadoop伪分布配置"><a href="#hadoop伪分布配置" class="headerlink" title="hadoop伪分布配置"></a>hadoop伪分布配置</h3><p>在设置 Hadoop 伪分布式配置前，我们还需要设置 HADOOP 环境变量，执行上面的环境配置即可</p>
<p>Hadoop 的配置文件位于 /usr/local/hadoop/etc/hadoop/ 中，伪分布式需要修改2个配置文件 core-site.xml 和 hdfs-site.xml 。Hadoop的配置文件是 xml 格式，每个配置以声明 property 的 name 和 value 的方式来实现。</p>
<pre><code>gedit ./etc/hadoop/core-site.xml
</code></pre><p>改为:</p>
<pre><code>&lt;configuration&gt;
&lt;property&gt;
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
    &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;
    &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>同样的修改 hdfs-site.xml</p>
<pre><code>gedit ./etc/hadoop/hdfs-site.xml
</code></pre><p>改为</p>
<pre><code>&lt;configuration&gt;
&lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
    &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
    &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>配置完成后，执行 NameNode 的格式化:</p>
<pre><code>./bin/hdfs namenode -format
</code></pre><h5 id="其实这里如果之前配置生效可以直接hdfs-namenode-format了"><a href="#其实这里如果之前配置生效可以直接hdfs-namenode-format了" class="headerlink" title="其实这里如果之前配置生效可以直接hdfs namenode -format了"></a>其实这里如果之前配置生效可以直接hdfs namenode -format了</h5><p>成功的话，会看到 “successfully formatted” 和 “Exitting with status 0” 的提示，若为 “Exitting with status 1” 则是出错。</p>
<p>接着开启 NaneNode 和 DataNode 守护进程：</p>
<pre><code>./sbin/start-dfs.sh
</code></pre><p>若出现如下 SSH 的提示 “Are you sure you want to continue connecting”，输入 yes 即可。</p>
<p>启动完成后，可以通过命令 jps 来判断是否成功启动，若成功启动则会列出如下进程: “NameNode”、”DataNode”和SecondaryNameNode（如果 SecondaryNameNode 没有启动，请运行 sbin/stop-dfs.sh 关闭进程，然后再次尝试启动尝试）。如果没有 NameNode 或 DataNode ，那就是配置不成功，请仔细检查之前步骤，或通过查看启动日志排查原因。（具体请参考ref链接）</p>
<p>成功启动后，可以访问 Web 界面 <a href="http://localhost:50070" target="_blank" rel="external">http://localhost:50070</a> 查看 NameNode 和 Datanode 信息，还可以在线查看 HDFS 中的文件。</p>
<h3 id="运行Hadoop伪分布式实例"><a href="#运行Hadoop伪分布式实例" class="headerlink" title="运行Hadoop伪分布式实例"></a>运行Hadoop伪分布式实例</h3><p>上面的单机模式，grep 例子读取的是本地数据，伪分布式读取的则是 HDFS 上的数据。要使用 HDFS，首先需要在 HDFS 中创建用户目录：</p>
<pre><code>./bin/hdfs dfs -mkdir -p /user/hadoop
</code></pre><p>接着将 ./etc/hadoop 中的 xml 文件作为输入文件复制到分布式文件系统中，即将 /usr/local/hadoop/etc/hadoop 复制到分布式文件系统中的 /user/hadoop/input 中。我们使用的是 hadoop 用户，并且已创建相应的用户目录 /user/hadoop ，因此在命令中就可以使用相对路径如 input，其对应的绝对路径就是 /user/hadoop/input:<br>wordcount测试：</p>
<pre><code>./bin/hdfs dfs -mkdir input
./bin/hdfs dfs -put ./etc/hadoop/*.xml input
</code></pre><p>复制完成后，可以通过如下命令查看 HDFS 中的文件列表：</p>
<pre><code>./bin/hdfs dfs -ls input
</code></pre><p>伪分布式运行 MapReduce 作业的方式跟单机模式相同，区别在于伪分布式读取的是HDFS中的文件（可以将单机步骤中创建的本地 input 文件夹，输出结果 output 文件夹都删掉来验证这一点）。</p>
<pre><code>./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce- 
examples-*.jar grep input output &apos;dfs[a-z.]+&apos;
</code></pre><p>查看运行结果的命令（查看的是位于 HDFS 中的输出结果）：</p>
<pre><code>./bin/hdfs dfs -cat output/*
</code></pre><p>我们也可以将运行结果取回到本地：</p>
<pre><code>rm -r ./output    # 先删除本地的 output 文件夹（如果存在）

./bin/hdfs dfs -get output ./output     # 将 HDFS 上的 output 文件夹    拷贝到本机
cat ./output/*
</code></pre><p>Hadoop 运行程序时，输出目录不能存在，否则会提示错误 “org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:9000/user/hadoop/output already exists” ，因此若要再次执行，需要执行如下命令删除 output 文件夹:</p>
<pre><code>./bin/hdfs dfs -rm -r output    # 删除 output 文件夹
</code></pre><p>若要关闭Hadoop,则运行：</p>
<pre><code>./sbin/stop-dfs.sh
</code></pre><blockquote>
<p>下次启动 hadoop 时，无需进行 NameNode 的初始化，只需要运行 ./sbin/start-dfs.sh 就可以！</p>
<p>若要运行wordcount 直接 (前提你建好文件夹用上述方法传文件进去 同样 output运行前不能存在</p>
</blockquote>
<pre><code>hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount /input /output    
</code></pre><h2 id="启动YARN"><a href="#启动YARN" class="headerlink" title="启动YARN"></a>启动YARN</h2><p>伪分布式不启动 YARN 也可以，一般不会影响程序执行）<br>YARN 是从 MapReduce 中分离出来的，负责资源管理与任务调度。YARN 运行于 MapReduce 之上，提供了高可用性、高扩展性，YARN 的更多介绍在此不展开，有兴趣的可查阅相关资料。</p>
<p>上述通过 ./sbin/start-dfs.sh 启动 Hadoop，仅仅是启动了 MapReduce 环境，我们可以启动 YARN ，让 YARN 来负责资源管理与任务调度。</p>
<p>首先修改配置文件 mapred-site.xml，这边需要先进行重命名</p>
<pre><code>mv ./etc/hadoop/mapred-site.xml.template ./etc/hadoop/mapred-site.xml
</code></pre><p>将其配置修改为:</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
         &lt;value&gt;yarn&lt;/value&gt;
      &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>接着修改配置文件 yarn-site.xml：</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>然后就可以开启yarn了：</p>
<pre><code>./sbin/start-yarn.sh      $ 启动YARN
./sbin/mr-jobhistory-daemon.sh start historyserver  # 开启历史服务器，才能在Web中查看任务运行情况
</code></pre><p>开启后通过 jps 查看，可以看到多了 NodeManager 和 ResourceManager 两个后台进程。</p>
<p>启动 YARN 之后，运行实例的方法还是一样的，仅仅是资源管理方式、任务调度不同。观察日志信息可以发现，不启用 YARN 时，是 “mapred.LocalJobRunner” 在跑任务，启用 YARN 之后，是 “mapred.YARNRunner” 在跑任务。启动 YARN 有个好处是可以通过 Web 界面查看任务的运行情况：<a href="http://localhost:8088/cluster" target="_blank" rel="external">http://localhost:8088/cluster</a></p>
<p>但 YARN 主要是为集群提供更好的资源管理与任务调度，然而这在单机上体现不出价值，反而会使程序跑得稍慢些。因此在单机上是否开启 YARN 就看实际情况了。</p>
<blockquote>
<p>不启动 YARN 需重命名 mapred-site.xml<br>如果不想启动 YARN，务必把配置文件 mapred-site.xml 重命名，改成mapred-site.xml.template，需要用时改回来就行。否则在该配置文件存在，而未开启 YARN 的情况下，运行程序会提示 “Retrying connect to server: 0.0.0.0/0.0.0.0:8032” 的错误，这也是为何该配置文件初始文件名为 mapred-site.xml.template。</p>
</blockquote>
<p>同样的，关闭 YARN 的脚本如下：</p>
<pre><code>./sbin/stop-yarn.sh
./sbin/mr-jobhistory-daemon.sh stop historyserver
</code></pre><blockquote>
<h1 id="Referene"><a href="#Referene" class="headerlink" title="Referene:"></a>Referene:</h1><p> <a href="http://www.powerxing.com/install-hadoop-in-centos/" target="_blank" rel="external">Hadoop安装教程_单机/伪分布式配置_CentOS6.4/Hadoop2.6.0</a><br><a href="http://blog.chinaunix.net/uid-28311809-id-4383551.html" target="_blank" rel="external">Yarn简单介绍及内存配置</a><br><a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html" target="_blank" rel="external">Hadoop: Setting up a Single Node Cluster.</a><br><a href="https://tecadmin.net/setup-hadoop-single-node-cluster-on-centos-redhat/" target="_blank" rel="external">How to Setup Hadoop 2.8 on CentOS, Ubuntu and LinuxMint</a></p>
</blockquote>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/hadoop-RedHat-wordcount/" rel="tag"># hadoop, RedHat, wordcount</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/04/18/hello-world/" rel="prev" title="Hello World">
                Hello World <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="ericyz-zhang" />
          <p class="site-author-name" itemprop="name">ericyz-zhang</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#创建用户"><span class="nav-number">1.</span> <span class="nav-text">创建用户</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#配置YUM源"><span class="nav-number">2.</span> <span class="nav-text">配置YUM源</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#添加sudoer"><span class="nav-number">3.</span> <span class="nav-text">添加sudoer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ssh免密码"><span class="nav-number">4.</span> <span class="nav-text">ssh免密码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#jdk环境配置"><span class="nav-number">5.</span> <span class="nav-text">jdk环境配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#设置环境变量"><span class="nav-number">5.1.</span> <span class="nav-text">设置环境变量</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hadoop单机配置"><span class="nav-number">6.</span> <span class="nav-text">hadoop单机配置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#配置环境变量"><span class="nav-number">7.</span> <span class="nav-text">配置环境变量</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#hadoop单机运行"><span class="nav-number">7.1.</span> <span class="nav-text">hadoop单机运行</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#注意，Hadoop-默认不会覆盖结果文件，因此再次运行上面实例会提示出错，需要先将-output-删除。"><span class="nav-number">7.1.0.1.</span> <span class="nav-text">注意，Hadoop 默认不会覆盖结果文件，因此再次运行上面实例会提示出错，需要先将 ./output 删除。</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hadoop伪分布配置"><span class="nav-number">7.2.</span> <span class="nav-text">hadoop伪分布配置</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#其实这里如果之前配置生效可以直接hdfs-namenode-format了"><span class="nav-number">7.2.0.1.</span> <span class="nav-text">其实这里如果之前配置生效可以直接hdfs namenode -format了</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#运行Hadoop伪分布式实例"><span class="nav-number">7.3.</span> <span class="nav-text">运行Hadoop伪分布式实例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#启动YARN"><span class="nav-number">8.</span> <span class="nav-text">启动YARN</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Referene"><span class="nav-number"></span> <span class="nav-text">Referene:</span></a></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ericyz-zhang</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  






  





  

  

  

  

  

</body>
</html>
